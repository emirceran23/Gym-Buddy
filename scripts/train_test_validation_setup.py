"""
Train/Test/Validation Video Dizin YapÄ±sÄ± iÃ§in ML Training Pipeline

Dizin yapÄ±sÄ±:
normal_video/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ true/
â”‚   â””â”€â”€ false/
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ true/
â”‚   â””â”€â”€ false/
â””â”€â”€ validation/
    â”œâ”€â”€ true/
    â””â”€â”€ false/
"""

# GOOGLE COLAB KURULUM KODU
colab_setup_code = '''
# 1. Paketleri yÃ¼kle
!pip install mediapipe opencv-python scikit-learn pandas numpy matplotlib joblib

# 2. Google Drive baÄŸla
from google.colab import drive
drive.mount('/content/drive')

# 3. Dizin yapÄ±sÄ±nÄ± ayarla
import os

# Video klasÃ¶r yollarÄ± (kendi yolunuza gÃ¶re deÄŸiÅŸtirin!)
VIDEOS_BASE_DIR = '/content/drive/MyDrive/normal_video'  # DEÄÄ°ÅTÄ°RÄ°N!

# Alt dizinler
TRAIN_DIR = f'{VIDEOS_BASE_DIR}/train'
TEST_DIR = f'{VIDEOS_BASE_DIR}/test'
VALIDATION_DIR = f'{VIDEOS_BASE_DIR}/validation'

# Output dizini
OUTPUT_DIR = '/content/output'
os.makedirs(OUTPUT_DIR, exist_ok=True)

# CSV Ã§Ä±ktÄ± dizinleri
for split in ['train', 'test', 'validation']:
    for label in ['true', 'false']:
        os.makedirs(f'{OUTPUT_DIR}/csv/{split}/{label}', exist_ok=True)

print("âœ“ Dizin yapÄ±sÄ± hazÄ±r!")
print(f"  Train: {TRAIN_DIR}")
print(f"  Test: {TEST_DIR}")
print(f"  Validation: {VALIDATION_DIR}")
print(f"  Output: {OUTPUT_DIR}")
'''

# VIDEO Ä°ÅLEME KODU (batch_process_videos fonksiyonunu gÃ¼ncelle)
batch_process_updated = '''
def batch_process_videos_traintest(split_name, split_dir, output_base_dir):
    """
    Train/Test/Validation split iÃ§in videolarÄ± iÅŸle
    
    Args:
        split_name: 'train', 'test', veya 'validation'
        split_dir: Split dizini (Ã¶rn: /path/to/train)
        output_base_dir: CSV Ã§Ä±ktÄ± dizini
    """
    print(f"\\n{'='*70}")
    print(f"{split_name.upper()} SPLIT Ä°ÅLENÄ°YOR")
    print(f"{'='*70}")
    
    results = {}
    
    # TRUE ve FALSE klasÃ¶rlerini iÅŸle
    for label in ['true', 'false']:
        label_dir = os.path.join(split_dir, label)
        output_csv_dir = os.path.join(output_base_dir, 'csv', split_name, label)
        
        if not os.path.exists(label_dir):
            print(f"âš ï¸  {label} klasÃ¶rÃ¼ bulunamadÄ±: {label_dir}")
            continue
        
        count = batch_process_videos(
            input_folder=label_dir,
            output_folder=output_csv_dir,
            prefix=label,
            category=f"{split_name.upper()} - {label.upper()}"
        )
        
        results[label] = count
    
    print(f"\\n{split_name.upper()} Ã¶zeti:")
    print(f"  TRUE: {results.get('true', 0)} video")
    print(f"  FALSE: {results.get('false', 0)} video")
    print(f"  TOPLAM: {sum(results.values())} video")
    
    return results


# TÃœM SPLIT'LERÄ° Ä°ÅLE
print("\\n" + "="*70)
print("VÄ°DEOLARDAN AÃ‡I Ã‡IKARIMI BAÅLIYOR")
print("="*70)

all_results = {}

# Train split
train_results = batch_process_videos_traintest('train', TRAIN_DIR, OUTPUT_DIR)
all_results['train'] = train_results

# Test split
test_results = batch_process_videos_traintest('test', TEST_DIR, OUTPUT_DIR)
all_results['test'] = test_results

# Validation split
val_results = batch_process_videos_traintest('validation', VALIDATION_DIR, OUTPUT_DIR)
all_results['validation'] = val_results

# GENEL Ã–ZET
print("\\n" + "="*70)
print("TÃœM VÄ°DEOLAR Ä°ÅLENDÄ° - Ã–ZET")
print("="*70)
for split_name, split_results in all_results.items():
    total = sum(split_results.values())
    print(f"{split_name.upper():12s}: {split_results.get('true', 0)} TRUE + {split_results.get('false', 0)} FALSE = {total} toplam")

grand_total = sum(sum(r.values()) for r in all_results.values())
print(f"\\nGRAND TOTAL: {grand_total} video iÅŸlendi")
print("="*70)
'''

# VERÄ° YÃœKLEME KODU (load_data fonksiyonunu gÃ¼ncelle)
load_data_updated = '''
def load_data_traintest(csv_base_dir):
    """
    Train/Test/Validation split'lerinden veri yÃ¼kle
    
    Args:
        csv_base_dir: CSV dosyalarÄ±nÄ±n bulunduÄŸu ana dizin
        
    Returns:
        Dict containing X_train, y_train, X_test, y_test, X_val, y_val, feature_names
    """
    import glob
    
    datasets = {}
    
    for split in ['train', 'test', 'validation']:
        # TRUE CSV'ler
        true_pattern = os.path.join(csv_base_dir, 'csv', split, 'true', 'output_true_*.csv')
        true_csvs = sorted(glob.glob(true_pattern))
        
        # FALSE CSV'ler
        false_pattern = os.path.join(csv_base_dir, 'csv', split, 'false', 'output_false_*.csv')
        false_csvs = sorted(glob.glob(false_pattern))
        
        print(f"\\n{split.upper()} split:")
        print(f"  TRUE: {len(true_csvs)} CSV")
        print(f"  FALSE: {len(false_csvs)} CSV")
        
        # Feature extraction
        features_list = []
        labels = []
        filenames = []
        
        # TRUE samples (label = 1)
        for csv_path in true_csvs:
            features = extract_features(csv_path)
            features_list.append(features)
            labels.append(1)
            filenames.append(os.path.basename(csv_path))
        
        # FALSE samples (label = 0)
        for csv_path in false_csvs:
            features = extract_features(csv_path)
            features_list.append(features)
            labels.append(0)
            filenames.append(os.path.basename(csv_path))
        
        # DataFrame oluÅŸtur
        if len(features_list) > 0:
            df_features = pd.DataFrame(features_list)
            X = df_features.values
            y = np.array(labels)
            
            datasets[split] = {
                'X': X,
                'y': y,
                'filenames': filenames,
                'feature_names': df_features.columns.tolist(),
                'df_features': df_features
            }
            
            print(f"  Veri boyutu: {X.shape}")
            print(f"  TRUE Ã¶rnekler: {sum(y)}")
            print(f"  FALSE Ã¶rnekler: {len(y) - sum(y)}")
        else:
            print(f"  âš ï¸  Veri bulunamadÄ±!")
            datasets[split] = None
    
    return datasets


# Veriyi yÃ¼kle
datasets = load_data_traintest(OUTPUT_DIR)

# Train, Test, Validation ayÄ±r
if datasets['train'] is not None:
    X_train = datasets['train']['X']
    y_train = datasets['train']['y']
    feature_names = datasets['train']['feature_names']
    print(f"\\nâœ“ TRAIN seti yÃ¼klendi: {X_train.shape}")

if datasets['test'] is not None:
    X_test = datasets['test']['X']
    y_test = datasets['test']['y']
    print(f"âœ“ TEST seti yÃ¼klendi: {X_test.shape}")

if datasets['validation'] is not None:
    X_val = datasets['validation']['X']
    y_val = datasets['validation']['y']
    print(f"âœ“ VALIDATION seti yÃ¼klendi: {X_val.shape}")
'''

# MODEL EÄÄ°TÄ°MÄ° (validation set ile)
train_with_validation = '''
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_val_scaled = scaler.transform(X_val) if datasets['validation'] is not None else None

print("\\n" + "="*70)
print("MODEL EÄÄ°TÄ°MÄ° BAÅLIYOR")
print("="*70)

# RandomForest eÄŸitimi
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    class_weight='balanced'
)

model.fit(X_train_scaled, y_train)
print("âœ“ Model eÄŸitildi!")

# TRAIN SET DEÄERLENDÄ°RMESÄ°
y_train_pred = model.predict(X_train_scaled)
train_accuracy = accuracy_score(y_train, y_train_pred)
print(f"\\nğŸ“Š TRAIN Accuracy: {train_accuracy:.2%}")

# TEST SET DEÄERLENDÄ°RMESÄ°
y_test_pred = model.predict(X_test_scaled)
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f"ğŸ“Š TEST Accuracy: {test_accuracy:.2%}")

# VALIDATION SET DEÄERLENDÄ°RMESÄ° (eÄŸer varsa)
if X_val_scaled is not None:
    y_val_pred = model.predict(X_val_scaled)
    val_accuracy = accuracy_score(y_val, y_val_pred)
    print(f"ğŸ“Š VALIDATION Accuracy: {val_accuracy:.2%}")
    
    print(f"\\n{'='*70}")
    print("VALIDATION SET - DetaylÄ± Rapor")
    print(f"{'='*70}")
    print(classification_report(y_val, y_val_pred, target_names=['YanlÄ±ÅŸ Form (0)', 'DoÄŸru Form (1)']))
    
    cm = confusion_matrix(y_val, y_val_pred)
    print(f"\\nConfusion Matrix (Validation):")
    print(f"                  Tahmin")
    print(f"                  0        1")
    print(f"GerÃ§ek  0        {cm[0,0]:3d}      {cm[0,1]:3d}")
    print(f"        1        {cm[1,0]:3d}      {cm[1,1]:3d}")

print(f"\\n{'='*70}")
print("TEST SET - DetaylÄ± Rapor")
print(f"{'='*70}")
print(classification_report(y_test, y_test_pred, target_names=['YanlÄ±ÅŸ Form (0)', 'DoÄŸru Form (1)']))

cm_test = confusion_matrix(y_test, y_test_pred)
print(f"\\nConfusion Matrix (Test):")
print(f"                  Tahmin")
print(f"                  0        1")
print(f"GerÃ§ek  0        {cm_test[0,0]:3d}      {cm_test[0,1]:3d}")
print(f"        1        {cm_test[1,0]:3d}      {cm_test[1,1]:3d}")
'''

# Ã–ZETÄ° YAZDIRMA
summary_text = """
=======================================================================
          TRAIN/TEST/VALIDATION SPLIT KULLANIM REHBERÄ°
=======================================================================

## DÄ°ZÄ°N YAPISI:

normal_video/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ true/
â”‚   â”‚   â”œâ”€â”€ true_1.mp4
â”‚   â”‚   â”œâ”€â”€ true_2.mp4
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ false/
â”‚       â”œâ”€â”€ false_1.mp4
â”‚       â”œâ”€â”€ false_2.mp4
â”‚       â””â”€â”€ ...
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ true/
â”‚   â””â”€â”€ false/
â””â”€â”€ validation/
    â”œâ”€â”€ true/
    â””â”€â”€ false/

## GOOGLE COLAB'DA KULLANIM:

1. YukarÄ±daki kod bloklarÄ±nÄ± sÄ±rayla Colab notebook'a kopyalayÄ±n
2. VIDEOS_BASE_DIR deÄŸiÅŸkenini kendi Drive yolunuza gÃ¶re dÃ¼zenleyin
3. HÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n

## FARKLAR:

- Eski yapÄ±: videos/true, videos/false (tek klasÃ¶r)
- Yeni yapÄ±: train/true, train/false, test/true, test/false, validation/true, validation/false

## Ã‡Ä°KTI:

output/
â”œâ”€â”€ csv/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ true/
â”‚   â”‚   â””â”€â”€ false/
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ true/
â”‚   â”‚   â””â”€â”€ false/
â”‚   â””â”€â”€ validation/
â”‚       â”œâ”€â”€ true/
â”‚       â””â”€â”€ false/
â”œâ”€â”€ biceps_model.pkl
â”œâ”€â”€ scaler.pkl
â””â”€â”€ feature_importance.csv

=======================================================================
"""

print(summary_text)

# Kod bloklarÄ±nÄ± yazdÄ±r
print("\n" + "="*70)
print("KOD BLOKLARI:")
print("="*70)

print("\n### BLOK 1: COLAB KURULUMU")
print(colab_setup_code)

print("\n### BLOK 2: VÄ°DEO Ä°ÅLEME (batch_process_videos fonksiyonundan SONRA ekleyin)")
print(batch_process_updated)

print("\n### BLOK 3: VERÄ° YÃœKLEME (load_data yerine kullanÄ±n)")
print(load_data_updated)

print("\n### BLOK 4: MODEL EÄÄ°TÄ°MÄ° (Validation ile)")
print(train_with_validation)
