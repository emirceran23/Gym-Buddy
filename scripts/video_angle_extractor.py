ekledim# -*- coding: utf-8 -*-
"""Video_Angle_Extractor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ox3ktbG8l-DHJEzvT6uoS-K0OexpiCzh

# ğŸ‹ï¸ Biceps Curl Form Classifier Training

Bu notebook, videolardan aÃ§Ä± Ã§Ä±kararak RandomForest Classifier modeli eÄŸitir.

## Pipeline:
1. **Video Ä°ÅŸleme**: MediaPipe ile frame-by-frame aÃ§Ä± Ã§Ä±karÄ±mÄ±
2. **Feature Extraction**: CSV'lerden 16 biyomekanik Ã¶zellik Ã§Ä±karÄ±mÄ±
3. **Model EÄŸitimi**: RandomForest Classifier ile sÄ±nÄ±flandÄ±rma
4. **DeÄŸerlendirme**: Accuracy, confusion matrix, feature importance

## ğŸ“¦ 1. Paket Kurulumu
"""

!pip install mediapipe opencv-python scikit-learn pandas numpy matplotlib joblib

"""## ğŸ“ 2. Google Drive BaÄŸlantÄ±sÄ± & Video YapÄ±sÄ±

VideolarÄ±n dizin yapÄ±sÄ± ÅŸu ÅŸekilde olmalÄ±:
```
/content/drive/MyDrive/videos/
â”œâ”€â”€ true/
â”‚   â”œâ”€â”€ true_1.mp4
â”‚   â”œâ”€â”€ true_2.mp4
â”‚   â””â”€â”€ ...
â””â”€â”€ false/
    â”œâ”€â”€ false_1.mp4
    â”œâ”€â”€ false_2.mp4
    â””â”€â”€ ...
```
"""

import zipfile
import os

zip_path = "/content/drive/MyDrive/GymBuddy/normal_video.zip"
extract_to = "/content/drive/MyDrive/GymBuddy/normal_video"

# KlasÃ¶r oluÅŸtur
os.makedirs(extract_to, exist_ok=True)

# ZIP Ã§Ä±karma
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print("âœ“ ZIP baÅŸarÄ±yla Ã§Ä±karÄ±ldÄ±!")
print("Ã‡Ä±karÄ±lan klasÃ¶r:", extract_to)

from google.colab import drive
drive.mount('/content/drive')

# Video klasÃ¶r yollarÄ±nÄ± ayarlayÄ±n
VIDEOS_BASE_DIR = '/content/drive/MyDrive/GymBuddy/normal_video/normal_video'  # DeÄŸiÅŸtirin!
TRAIN_DIR = f'{VIDEOS_BASE_DIR}/train'
TEST_DIR = f'{VIDEOS_BASE_DIR}/test'
VALIDATION_DIR = f'{VIDEOS_BASE_DIR}/validation'
TRUE_VIDEOS_DIR = f'{VIDEOS_BASE_DIR}/true'
FALSE_VIDEOS_DIR = f'{VIDEOS_BASE_DIR}/false'
OUTPUT_DIR = '/content/output'

for split in ['train', 'test', 'validation']:
    for label in ['true', 'false']:
        os.makedirs(f'{OUTPUT_DIR}/csv/{split}/{label}', exist_ok=True)

print(f"âœ“ Train: {TRAIN_DIR}")
print(f"âœ“ Test: {TEST_DIR}")
print(f"âœ“ Validation: {VALIDATION_DIR}")

"""## ğŸ¯ 3. Ana SÄ±nÄ±flar ve Fonksiyonlar"""

import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import os
import glob
from pathlib import Path
from typing import Optional, Tuple, Dict, List
from collections import deque


class BicepsCurlCounter:
    """Rep sayÄ±mÄ± ve form deÄŸerlendirmesi iÃ§in sÄ±nÄ±f"""

    def __init__(self):
        self.left_reps = 0
        self.right_reps = 0
        self.left_correct_reps = 0
        self.right_correct_reps = 0
        self.left_state = 'down'
        self.right_state = 'down'
        self.left_cycle_index = 0
        self.right_cycle_index = 0

        # Smoothing
        self.left_angle_history = deque(maxlen=5)
        self.right_angle_history = deque(maxlen=5)

        # Thresholds
        self.up_threshold = 60
        self.down_threshold = 140
        self.alignment_threshold = 30

    def get_smoothed_angle(self, angle, history):
        if angle is not None:
            history.append(angle)
        if len(history) == 0:
            return None
        return sum(history) / len(history)

    def update(self, left_angle, right_angle, left_aligned, right_aligned, left_elbow_align, right_elbow_align):
        # Smooth angles
        left_smoothed = self.get_smoothed_angle(left_angle, self.left_angle_history)
        right_smoothed = self.get_smoothed_angle(right_angle, self.right_angle_history)

        # Left arm rep counting
        if left_smoothed is not None:
            if self.left_state == 'down' and left_smoothed < self.up_threshold:
                self.left_state = 'up'
            elif self.left_state == 'up' and left_smoothed > self.down_threshold:
                self.left_state = 'down'
                self.left_reps += 1
                self.left_cycle_index += 1
                if left_aligned and left_elbow_align < self.alignment_threshold:
                    self.left_correct_reps += 1

        # Right arm rep counting
        if right_smoothed is not None:
            if self.right_state == 'down' and right_smoothed < self.up_threshold:
                self.right_state = 'up'
            elif self.right_state == 'up' and right_smoothed > self.down_threshold:
                self.right_state = 'down'
                self.right_reps += 1
                self.right_cycle_index += 1
                if right_aligned and right_elbow_align < self.alignment_threshold:
                    self.right_correct_reps += 1

        return {
            'left_reps': self.left_reps,
            'right_reps': self.right_reps,
            'left_correct_reps': self.left_correct_reps,
            'right_correct_reps': self.right_correct_reps,
            'total_reps': self.left_reps + self.right_reps,
            'left_state': self.left_state,
            'right_state': self.right_state,
            'left_cycle_index': self.left_cycle_index,
            'right_cycle_index': self.right_cycle_index,
            'left_smoothed_angle': left_smoothed,
            'right_smoothed_angle': right_smoothed
        }


class VideoAngleExtractor:
    """MediaPipe kullanarak videodan aÃ§Ä± Ã§Ä±kartÄ±cÄ±"""

    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

    def calculate_angle(self, p1, p2, p3):
        if None in [p1, p2, p3]:
            return None
        v1 = np.array(p1) - np.array(p2)
        v2 = np.array(p3) - np.array(p2)
        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)
        cos_angle = np.clip(cos_angle, -1.0, 1.0)
        return np.degrees(np.arccos(cos_angle))

    def get_landmark(self, landmarks, idx, w, h):
        if not landmarks:
            return None
        lm = landmarks.landmark[idx]
        if lm.visibility < 0.5:
            return None
        return (lm.x * w, lm.y * h)

    def check_alignment(self, shoulder, elbow, hip, torso_height):
        if None in [shoulder, elbow, hip]:
            return True
        elbow_offset = abs(elbow[0] - shoulder[0])
        max_deviation = torso_height * 0.15
        return elbow_offset < max_deviation

    def process_video(self, video_path: str, output_csv_path: str) -> pd.DataFrame:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"Video aÃ§Ä±lamadÄ±: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        counter = BicepsCurlCounter()
        results = []
        frame_idx = 0

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame_idx += 1
            h, w = frame.shape[:2]

            # MediaPipe iÅŸleme
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pose_results = self.pose.process(frame_rgb)
            landmarks = pose_results.pose_landmarks

            # Landmark'larÄ± al
            left_shoulder = self.get_landmark(landmarks, 11, w, h)
            left_elbow = self.get_landmark(landmarks, 13, w, h)
            left_wrist = self.get_landmark(landmarks, 15, w, h)
            left_hip = self.get_landmark(landmarks, 23, w, h)

            right_shoulder = self.get_landmark(landmarks, 12, w, h)
            right_elbow = self.get_landmark(landmarks, 14, w, h)
            right_wrist = self.get_landmark(landmarks, 16, w, h)
            right_hip = self.get_landmark(landmarks, 24, w, h)

            # Kol aÃ§Ä±larÄ±nÄ± hesapla (biceps curl angle)
            left_arm_angle = self.calculate_angle(left_shoulder, left_elbow, left_wrist)
            right_arm_angle = self.calculate_angle(right_shoulder, right_elbow, right_wrist)

            # Dirsek hizalama aÃ§Ä±larÄ± (elbow-shoulder-hip)
            left_elbow_align = self.calculate_angle(left_elbow, left_shoulder, left_hip)
            right_elbow_align = self.calculate_angle(right_elbow, right_shoulder, right_hip)

            # True torso angles (hip-shoulder-vertical)
            left_true_torso = None
            right_true_torso = None
            if left_shoulder and left_hip:
                vertical_left = (left_shoulder[0], left_shoulder[1] - 100)
                left_true_torso = self.calculate_angle(vertical_left, left_shoulder, left_hip)
            if right_shoulder and right_hip:
                vertical_right = (right_shoulder[0], right_shoulder[1] - 100)
                right_true_torso = self.calculate_angle(vertical_right, right_shoulder, right_hip)

            # Alignment check
            left_torso_height = abs(left_hip[1] - left_shoulder[1]) if left_hip and left_shoulder else 100
            right_torso_height = abs(right_hip[1] - right_shoulder[1]) if right_hip and right_shoulder else 100
            left_aligned = self.check_alignment(left_shoulder, left_elbow, left_hip, left_torso_height)
            right_aligned = self.check_alignment(right_shoulder, right_elbow, right_hip, right_torso_height)

            # Rep counter update
            status = counter.update(
                left_arm_angle, right_arm_angle,
                left_aligned, right_aligned,
                left_elbow_align or 999, right_elbow_align or 999
            )

            # Row oluÅŸtur
            time_sec = frame_idx / fps if fps > 0 else 0
            row = {
                'frame': frame_idx,
                'time_s': round(time_sec, 3),
                'left_cycle_index': status['left_cycle_index'],
                'right_cycle_index': status['right_cycle_index'],
                'left_state': status['left_state'],
                'right_state': status['right_state'],
                'left_angle_raw_deg': round(left_arm_angle, 2) if left_arm_angle else '',
                'right_angle_raw_deg': round(right_arm_angle, 2) if right_arm_angle else '',
                'left_angle_smoothed_deg': round(status['left_smoothed_angle'], 2) if status['left_smoothed_angle'] else '',
                'right_angle_smoothed_deg': round(status['right_smoothed_angle'], 2) if status['right_smoothed_angle'] else '',
                'left_elbow_alignment_angle_deg': round(left_elbow_align, 2) if left_elbow_align else '',
                'right_elbow_alignment_angle_deg': round(right_elbow_align, 2) if right_elbow_align else '',
                'left_true_torso_angle_deg': round(left_true_torso, 2) if left_true_torso else '',
                'right_true_torso_angle_deg': round(right_true_torso, 2) if right_true_torso else '',
                'left_aligned': int(left_aligned),
                'right_aligned': int(right_aligned),
                'left_reps': status['left_reps'],
                'right_reps': status['right_reps'],
                'left_correct_reps': status['left_correct_reps'],
                'right_correct_reps': status['right_correct_reps'],
                'total_reps': status['total_reps']
            }
            results.append(row)

            # Progress
            if frame_idx % 50 == 0:
                print(f"  {frame_idx}/{frame_count} ({100*frame_idx/frame_count:.0f}%)", end='\r')

        cap.release()

        df = pd.DataFrame(results)
        df.to_csv(output_csv_path, index=False)

        return df


print("âœ“ SÄ±nÄ±flar yÃ¼klendi!")

"""## ğŸ¬ 4. TÃ¼m VideolarÄ± Ä°ÅŸle ve CSV Ã‡Ä±kart"""

def batch_process_videos(input_folder, output_folder, prefix, category):
    """Videolardan CSV Ã§Ä±kart"""
    os.makedirs(output_folder, exist_ok=True)

    video_extensions = ['.mp4', '.avi', '.mov', '.MOV']
    video_files = []
    for ext in video_extensions:
        video_files.extend(list(Path(input_folder).glob(f'*{ext}')))  # TÃœM videolarÄ± al

    print(f"\n{'='*60}")
    print(f"{category} VIDEOLARI Ä°ÅLENÄ°YOR")
    print(f"Bulunan video sayÄ±sÄ±: {len(video_files)}")
    print(f"{'='*60}")

    extractor = VideoAngleExtractor()
    successful = 0

    for idx, video_path in enumerate(sorted(video_files), 1):
        print(f"\n[{idx}/{len(video_files)}] {video_path.name}")

        try:
            # Video numarasÄ±nÄ± al
            import re
            match = re.search(r'_(\d+)', video_path.stem)
            video_num = match.group(1) if match else str(idx)

            output_csv = f"{output_folder}/output_{prefix}_{video_num}.csv"
            df = extractor.process_video(str(video_path), output_csv)
            print(f"  âœ“ {len(df)} frame iÅŸlendi")
            successful += 1
        except Exception as e:
            print(f"  âœ— Hata: {e}")

    print(f"\nâœ“ {successful}/{len(video_files)} video baÅŸarÄ±yla iÅŸlendi")
    return successful


def process_all_splits():
    """Train/Test/Validation split'lerini iÅŸle"""

    all_results = {}

    # TRAIN split
    print(f"\n{'='*70}")
    print("TRAIN SPLIT Ä°ÅLENÄ°YOR")
    print(f"{'='*70}")

    train_true = batch_process_videos(
        f'{TRAIN_DIR}/true',
        f'{OUTPUT_DIR}/csv/train/true',
        'true',
        'TRAIN - TRUE'
    )
    train_false = batch_process_videos(
        f'{TRAIN_DIR}/false',
        f'{OUTPUT_DIR}/csv/train/false',
        'false',
        'TRAIN - FALSE'
    )
    all_results['train'] = {'true': train_true, 'false': train_false}

    # TEST split
    print(f"\n{'='*70}")
    print("TEST SPLIT Ä°ÅLENÄ°YOR")
    print(f"{'='*70}")

    test_true = batch_process_videos(
        f'{TEST_DIR}/true',
        f'{OUTPUT_DIR}/csv/test/true',
        'true',
        'TEST - TRUE'
    )
    test_false = batch_process_videos(
        f'{TEST_DIR}/false',
        f'{OUTPUT_DIR}/csv/test/false',
        'false',
        'TEST - FALSE'
    )
    all_results['test'] = {'true': test_true, 'false': test_false}

    # VALIDATION split
    print(f"\n{'='*70}")
    print("VALIDATION SPLIT Ä°ÅLENÄ°YOR")
    print(f"{'='*70}")

    val_true = batch_process_videos(
        f'{VALIDATION_DIR}/true',
        f'{OUTPUT_DIR}/csv/validation/true',
        'true',
        'VALIDATION - TRUE'
    )
    val_false = batch_process_videos(
        f'{VALIDATION_DIR}/false',
        f'{OUTPUT_DIR}/csv/validation/false',
        'false',
        'VALIDATION - FALSE'
    )
    all_results['validation'] = {'true': val_true, 'false': val_false}

    # Ã–zet
    print(f"\n{'='*70}")
    print("TÃœM SPLIT'LER Ä°ÅLENDÄ°")
    print(f"{'='*70}")
    for split, results in all_results.items():
        total = results['true'] + results['false']
        print(f"{split.upper():12s}: {results['true']} true + {results['false']} false = {total} toplam")

    return all_results


# TÃ¼m videolarÄ± iÅŸle
results = process_all_splits()

"""## ğŸ“Š 5. Feature Extraction (16 Ã–zellik)"""

def extract_features(csv_path: str) -> Dict[str, float]:
    """
    CSV'den 16 biyomekanik Ã¶zellik Ã§Ä±kart:
    - rom: Range of Motion
    - true_torso_stability_left_mean/std: Sol gÃ¶vde stabilitesi
    - true_torso_stability_right_mean/std: SaÄŸ gÃ¶vde stabilitesi
    - bilateral_true_torso_mean/std: Ä°ki taraflÄ± gÃ¶vde stabilitesi
    - tempo: Rep baÅŸÄ±na sÃ¼re
    - symmetry: Sol-saÄŸ simetri
    - movement_smoothness: Hareket akÄ±cÄ±lÄ±ÄŸÄ±
    - peak_flexion/extension: Min/max aÃ§Ä±lar
    - total_reps: Toplam rep
    - correct_rep_ratio: DoÄŸru rep oranÄ±
    - angle_cv: AÃ§Ä± varyasyon katsayÄ±sÄ±
    - frame_count: Frame sayÄ±sÄ±
    """
    try:
        df = pd.read_csv(csv_path)
        features = {}

        # 1. ROM
        left_angles = pd.to_numeric(df['left_angle_smoothed_deg'], errors='coerce').dropna()
        right_angles = pd.to_numeric(df['right_angle_smoothed_deg'], errors='coerce').dropna()
        all_angles = pd.concat([left_angles, right_angles])
        features['rom'] = float(all_angles.max() - all_angles.min()) if len(all_angles) > 0 else 0.0

        # 2-3. True Torso Stability - Left
        left_torso = pd.to_numeric(df['left_true_torso_angle_deg'], errors='coerce').dropna()
        features['true_torso_stability_left_mean'] = float(left_torso.mean()) if len(left_torso) > 0 else 0.0
        features['true_torso_stability_left_std'] = float(left_torso.std()) if len(left_torso) > 0 else 0.0

        # 4. Tempo
        total_reps = df['total_reps'].iloc[-1] if len(df) > 0 else 0
        total_time = df['time_s'].iloc[-1] if len(df) > 0 else 0
        features['tempo'] = float(total_time / total_reps) if total_reps > 0 else 0.0

        # 5. Symmetry
        if len(left_angles) > 1 and len(right_angles) > 1:
            min_len = min(len(left_angles), len(right_angles))
            corr = np.corrcoef(left_angles.iloc[:min_len].values, right_angles.iloc[:min_len].values)[0, 1]
            features['symmetry'] = float(corr) if not np.isnan(corr) else 0.0
        else:
            features['symmetry'] = 0.0

        # 6-7. True Torso Stability - Right
        right_torso = pd.to_numeric(df['right_true_torso_angle_deg'], errors='coerce').dropna()
        features['true_torso_stability_right_mean'] = float(right_torso.mean()) if len(right_torso) > 0 else 0.0
        features['true_torso_stability_right_std'] = float(right_torso.std()) if len(right_torso) > 0 else 0.0

        # 8-9. Bilateral True Torso
        all_torso = pd.concat([left_torso, right_torso])
        features['bilateral_true_torso_mean'] = float(all_torso.mean()) if len(all_torso) > 0 else 0.0
        features['bilateral_true_torso_std'] = float(all_torso.std()) if len(all_torso) > 0 else 0.0

        # 10. Movement Smoothness
        all_changes = pd.concat([left_angles.diff().abs().dropna(), right_angles.diff().abs().dropna()])
        avg_change = all_changes.mean()
        features['movement_smoothness'] = float(1.0 / (avg_change + 1e-6)) if len(all_changes) > 0 else 0.0

        # 11-12. Peak Flexion/Extension
        features['peak_flexion'] = float(all_angles.min()) if len(all_angles) > 0 else 0.0
        features['peak_extension'] = float(all_angles.max()) if len(all_angles) > 0 else 0.0

        # 13. Total Reps
        features['total_reps'] = float(total_reps)

        # 14. Correct Rep Ratio
        left_correct = df['left_correct_reps'].iloc[-1] if len(df) > 0 else 0
        right_correct = df['right_correct_reps'].iloc[-1] if len(df) > 0 else 0
        total_correct = left_correct + right_correct
        total_reps_both = total_reps * 2
        features['correct_rep_ratio'] = float(total_correct / total_reps_both) if total_reps_both > 0 else 0.0

        # 15. Angle CV
        angle_mean = all_angles.mean()
        angle_std = all_angles.std()
        features['angle_cv'] = float(angle_std / angle_mean) if angle_mean > 0 else 0.0

        # 16. Frame Count
        features['frame_count'] = float(len(df))

        return features

    except Exception as e:
        print(f"Hata: {e}")
        return {k: 0.0 for k in ['rom', 'true_torso_stability_left_mean', 'true_torso_stability_left_std',
                                  'tempo', 'symmetry', 'true_torso_stability_right_mean',
                                  'true_torso_stability_right_std', 'bilateral_true_torso_mean',
                                  'bilateral_true_torso_std', 'movement_smoothness', 'peak_flexion',
                                  'peak_extension', 'total_reps', 'correct_rep_ratio', 'angle_cv', 'frame_count']}

print("âœ“ Feature extraction fonksiyonu yÃ¼klendi!")

"""## ğŸ“ˆ 6. Veri YÃ¼kleme ve Feature Ã‡Ä±karÄ±mÄ±"""

def load_split_data(csv_base_dir, split_name):
    """Belirli bir split'ten veri yÃ¼kle"""

    true_csvs = sorted(glob.glob(f'{csv_base_dir}/csv/{split_name}/true/output_true_*.csv'))
    false_csvs = sorted(glob.glob(f'{csv_base_dir}/csv/{split_name}/false/output_false_*.csv'))

    print(f"\n{split_name.upper()} Split:")
    print(f"  TRUE: {len(true_csvs)}")
    print(f"  FALSE: {len(false_csvs)}")

    features_list = []
    labels = []
    filenames = []

    # TRUE samples
    for csv_path in true_csvs:
        features = extract_features(csv_path)
        features_list.append(features)
        labels.append(1)
        filenames.append(os.path.basename(csv_path))

    # FALSE samples
    for csv_path in false_csvs:
        features = extract_features(csv_path)
        features_list.append(features)
        labels.append(0)
        filenames.append(os.path.basename(csv_path))

    df_features = pd.DataFrame(features_list)
    X = df_features.values
    y = np.array(labels)

    return X, y, filenames, df_features.columns.tolist(), df_features


# Train, Test, Validation veri setlerini yÃ¼kle
X_train, y_train, train_files, feature_names, df_train = load_split_data(OUTPUT_DIR, 'train')
X_test, y_test, test_files, _, df_test = load_split_data(OUTPUT_DIR, 'test')
X_val, y_val, val_files, _, df_val = load_split_data(OUTPUT_DIR, 'validation')

print("\nâœ“ TÃ¼m veri setleri yÃ¼klendi!")
print(f"  TRAIN: {X_train.shape}")
print(f"  TEST: {X_test.shape}")
print(f"  VALIDATION: {X_val.shape}")

# Feature istatistikleri
print("\nğŸ“Š FEATURE Ä°STATÄ°STÄ°KLERÄ°:")
print("="*60)
df_features.describe().round(2)

"""## ğŸ¤– 7. Professional ML Pipeline: Train+Val+5-Fold CV"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score,
    f1_score,
    recall_score,
    make_scorer
)
import matplotlib.pyplot as plt
import numpy as np
import joblib

##############################################################################
# PROFESYONEL ML PIPELINE
# 1. Train+Val BirleÅŸtir â†’ 96 samples
# 2. 5-Fold StratifiedKFold ile Hyperparam Tuning
# 3. OOF Predictions ile Threshold Tuning  
# 4. Test set (27 samples) SADECE EN SON
##############################################################################

print("="*70)
print("PROFESYONEL ML PIPELINE BAÅLIYOR")
print("="*70)

# ============================================================================
# 1. TRAIN + VALIDATION BÄ°RLEÅTÄ°R (96 samples)
# ============================================================================

print(f"\n{'='*70}")
print("1. VERÄ° HAZIRLIÄI: TRAIN+VAL BÄ°RLEÅTÄ°RME")
print(f"{'='*70}")

X_trainval = np.vstack([X_train, X_val])
y_trainval = np.concatenate([y_train, y_val])

print(f"âœ“ Train: {X_train.shape} (eÄŸitim seti)")
print(f"âœ“ Validation: {X_val.shape} (validation seti)")  
print(f"âœ“ Train+Val BirleÅŸtirildi: {X_trainval.shape}")
print(f"âœ“ Test (holdout): {X_test.shape} - SADECE FINAL EVALUATION Ä°Ã‡Ä°N")

print(f"\nSÄ±nÄ±f daÄŸÄ±lÄ±mÄ± (Train+Val):")
true_count = sum(y_trainval)
false_count = len(y_trainval) - true_count
print(f"  TRUE (DoÄŸru Form): {true_count} ({100*true_count/len(y_trainval):.1f}%)")
print(f"  FALSE (YanlÄ±ÅŸ Form): {false_count} ({100*false_count/len(y_trainval):.1f}%)")

# ============================================================================
# 2. FEATURE SCALING
# ============================================================================

scaler = StandardScaler()
X_trainval_scaled = scaler.fit_transform(X_trainval)
X_test_scaled = scaler.transform(X_test)

print(f"\nâœ“ Feature scaling tamamlandÄ±")

# ============================================================================
# 3. HYPERPARAMETER TUNING - 5-FOLD STRATIFIED CV
# ============================================================================

print(f"\n{'='*70}")
print("2. HYPERPARAMETER TUNING (5-Fold Stratified CV)")
print(f"{'='*70}")

# 5-Fold Stratified Cross-Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Custom scorers
recall_false = make_scorer(recall_score, pos_label=0)

scoring = {
    'accuracy': 'accuracy',
    'f1_macro': 'f1_macro',
    'recall_false': recall_false
}

# Parameter grid
param_grid = {
    'n_estimators': [50, 70, 100],
    'max_depth': [5, 7, 10, 12],
    'min_samples_split': [5, 8, 10],
    'min_samples_leaf': [2, 4, 6],
    'max_features': ['sqrt', 'log2', 0.5]
}

# Base model
base_model = RandomForestClassifier(
    random_state=42,
    class_weight={0: 2.5, 1: 1},  # False sÄ±nÄ±fÄ±na aÄŸÄ±rlÄ±k
    n_jobs=-1
)

# GridSearchCV
grid_search = GridSearchCV(
    estimator=base_model,
    param_grid=param_grid,
    scoring=scoring,
    refit='f1_macro',
    cv=cv,
    n_jobs=-1,
    verbose=1,
    return_train_score=True
)

print("\nğŸ” Grid Search baÅŸlÄ±yor...")
print(f"   Toplam kombinasyon: {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf']) * len(param_grid['max_features'])}")
print(f"   5-Fold CV ile deÄŸerlendirilecek")

grid_search.fit(X_trainval_scaled, y_trainval)

# Best parameters
print(f"\n{'='*70}")
print("EN Ä°YÄ° PARAMETRELER (5-Fold CV)")
print(f"{'='*70}")
for param, value in grid_search.best_params_.items():
    print(f"  {param}: {value}")

best_idx = grid_search.best_index_
print(f"\nCV SkorlarÄ± (En iyi model):")
print(f"  mean_test_accuracy    : {grid_search.cv_results_['mean_test_accuracy'][best_idx]:.4f}")
print(f"  mean_test_f1_macro    : {grid_search.cv_results_['mean_test_f1_macro'][best_idx]:.4f}")
print(f"  mean_test_recall_false: {grid_search.cv_results_['mean_test_recall_false'][best_idx]:.4f}")

best_model = grid_search.best_estimator_

# ============================================================================
# 4. OUT-OF-FOLD (OOF) PREDICTIONS for THRESHOLD TUNING
# ============================================================================

print(f"\n{'='*70}")
print("3. OUT-OF-FOLD (OOF) PREDICTIONS for THRESHOLD TUNING")
print(f"{'='*70}")

oof_proba = np.zeros(len(y_trainval))

cv_oof = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

print("OOF predictions hesaplanÄ±yor...")
for fold, (train_idx, val_idx) in enumerate(cv_oof.split(X_trainval_scaled, y_trainval), 1):
    X_fold_train = X_trainval_scaled[train_idx]
    y_fold_train = y_trainval[train_idx]
    X_fold_val = X_trainval_scaled[val_idx]
    
    fold_model = RandomForestClassifier(
        **grid_search.best_params_,
        random_state=42,
        class_weight={0: 2.5, 1: 1},
        n_jobs=-1
    )
    fold_model.fit(X_fold_train, y_fold_train)
    oof_proba[val_idx] = fold_model.predict_proba(X_fold_val)[:, 1]
    
    print(f"  Fold {fold}/5 tamamlandÄ±")

print(f"âœ“ OOF predictions hazÄ±r")

# ============================================================================
# 5. THRESHOLD TUNING (OOF)
# ============================================================================

print(f"\n{'='*70}")
print("4. THRESHOLD TUNING (OOF Probabilities)")
print(f"{'='*70}")

thresholds = np.arange(0.2, 0.8, 0.05)
best_threshold = 0.5
best_oof_f1 = 0

print(f"\n{'Threshold':<12} {'F1-Macro':<12} {'Recall(0)':<12} {'Recall(1)':<12}")
print("-"*50)

for threshold in thresholds:
    oof_preds = (oof_proba >= threshold).astype(int)
    f1m = f1_score(y_trainval, oof_preds, average='macro', zero_division=0)
    rec0 = recall_score(y_trainval, oof_preds, pos_label=0, zero_division=0)
    rec1 = recall_score(y_trainval, oof_preds, pos_label=1, zero_division=0)
    
    print(f"{threshold:<12.2f} {f1m:<12.4f} {rec0:<12.4f} {rec1:<12.4f}")
    
    if f1m > best_oof_f1:
        best_oof_f1 = f1m
        best_threshold = threshold

print(f"\nâœ… En iyi threshold: {best_threshold:.2f}")
print(f"   OOF F1-Macro: {best_oof_f1:.4f}")

# ============================================================================
# 6. FINAL MODEL TRAINING (TÃ¼m Train+Val)
# ============================================================================

print(f"\n{'='*70}")
print("5. FINAL MODEL EÄÄ°TÄ°MÄ° (TÃ¼m Train+Val ile)")
print(f"{'='*70}")

final_model = RandomForestClassifier(
    **grid_search.best_params_,
    random_state=42,
    class_weight={0: 2.5, 1: 1},
    n_jobs=-1
)

final_model.fit(X_trainval_scaled, y_trainval)
print(f"âœ“ Final model eÄŸitildi ({len(X_trainval)} sample)")

# ============================================================================
# 7. TEST SET EVALUATION (SADECE BÄ°R KEZ!)
# ============================================================================

print(f"\n{'='*70}")
print("6. FINAL TEST SET DEÄERLENDÄ°RMESÄ°")
print(f"{'='*70}")
print("âš ï¸  TEST SET SADECE BU NOKTADA Ä°LK VE SON KEZ KULLANILIYOR!")

test_proba = final_model.predict_proba(X_test_scaled)[:, 1]
test_preds_default = final_model.predict(X_test_scaled)
test_preds_tuned = (test_proba >= best_threshold).astype(int)

# Metrics
test_acc_default = accuracy_score(y_test, test_preds_default)
test_f1_default = f1_score(y_test, test_preds_default, average='macro', zero_division=0)
test_acc_tuned = accuracy_score(y_test, test_preds_tuned)
test_f1_tuned = f1_score(y_test, test_preds_tuned, average='macro', zero_division=0)

print(f"\nğŸ“Š TEST METRICS ({len(X_test)} samples):")
print(f"  Default threshold (0.50):")
print(f"    Accuracy: {test_acc_default:.4f} ({test_acc_default:.2%})")
print(f"    F1-Macro: {test_f1_default:.4f} ({test_f1_default:.2%})")
print(f"\n  Tuned threshold ({best_threshold:.2f}):")
print(f"    Accuracy: {test_acc_tuned:.4f} ({test_acc_tuned:.2%})")
print(f"    F1-Macro: {test_f1_tuned:.4f} ({test_f1_tuned:.2%})")

print(f"\n{'='*70}")
print(f"CLASSIFICATION REPORT (Test, Threshold={best_threshold:.2f})")
print(f"{'='*70}")
print(classification_report(
    y_test, test_preds_tuned,
    target_names=['YanlÄ±ÅŸ Form (0)', 'DoÄŸru Form (1)'],
    zero_division=0
))

cm = confusion_matrix(y_test, test_preds_tuned)
print(f"\nConfusion Matrix (Test, threshold={best_threshold:.2f}):")
print(f"                  Tahmin")
print(f"                  0        1")
print(f"GerÃ§ek  0        {cm[0,0]:3d}      {cm[0,1]:3d}")
print(f"        1        {cm[1,0]:3d}      {cm[1,1]:3d}")

# ============================================================================
# 8. FEATURE IMPORTANCE
# ============================================================================

print(f"\n{'='*70}")
print("7. FEATURE IMPORTANCE ANALYSIS")
print(f"{'='*70}")

feature_importance = pd.DataFrame({
    'feature': feature_names,
    'importance': final_model.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_importance.to_string(index=False))

# Visualization
plt.figure(figsize=(10, 6))
plt.barh(range(len(feature_importance)), feature_importance['importance'].values, color='steelblue')
plt.yticks(range(len(feature_importance)), feature_importance['feature'].values)
plt.xlabel('Importance Score', fontsize=12)
plt.ylabel('Feature', fontsize=12)
plt.title('Feature Importance (5-Fold CV RandomForest)', fontsize=14, fontweight='bold')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"\nâœ“ Feature importance plot kaydedildi")

# ============================================================================
# 9. MODEL VE Ã‡IKTILAR KAYDET
# ============================================================================

print(f"\n{'='*70}")
print("8. MODEL VE Ã‡IKTILAR KAYDEDÄ°LÄ°YOR")
print(f"{'='*70}")

model_path = f'{OUTPUT_DIR}/biceps_model_final.pkl'
scaler_path = f'{OUTPUT_DIR}/scaler_final.pkl'
threshold_path = f'{OUTPUT_DIR}/best_threshold.txt'

joblib.dump(final_model, model_path)
joblib.dump(scaler, scaler_path)
with open(threshold_path, 'w') as f:
    f.write(str(best_threshold))

feature_importance.to_csv(f'{OUTPUT_DIR}/feature_importance.csv', index=False)

print(f"âœ“ Model: {model_path}")
print(f"âœ“ Scaler: {scaler_path}")
print(f"âœ“ Best Threshold: {best_threshold:.2f} ({threshold_path})")
print(f"âœ“ Feature Importance: {OUTPUT_DIR}/feature_importance.csv")

print(f"\n{'='*70}")
print("PIPELINE TAMAMLANDI! ğŸ‰")
print(f"{'='*70}")
print(f"\nğŸ“Š Final SonuÃ§lar:")
print(f"  Train+Val: {len(X_trainval)} samples (5-Fold CV ile tune edildi)")
print(f"  Test: {len(X_test)} samples")
print(f"  En iyi threshold: {best_threshold:.2f}")
print(f"  Test Accuracy: {test_acc_tuned:.2%}")
print(f"  Test F1-Macro: {test_f1_tuned:.2%}")


"""## ğŸ“¥ 10. DosyalarÄ± Ä°ndir"""

from google.colab import files

# Model dosyalarÄ±nÄ± indir
print("Model dosyalarÄ± indiriliyor...")
files.download(model_path)
files.download(scaler_path)
files.download(f'{OUTPUT_DIR}/feature_importance.csv')
files.download(f'{OUTPUT_DIR}/feature_importance.png')

print("\nâœ“ TÃ¼m dosyalar indirildi!")

"""## ğŸ”® 11. Yeni Video Test Etme (Opsiyonel)"""

def predict_video(video_path):
    """Yeni bir video iÃ§in form skoru hesapla"""

    print(f"Video iÅŸleniyor: {video_path}")

    # GeÃ§ici CSV oluÅŸtur
    temp_csv = '/content/temp_video.csv'
    extractor = VideoAngleExtractor()
    df = extractor.process_video(video_path, temp_csv)

    # Feature Ã§Ä±kart
    features = extract_features(temp_csv)

    # Tahmin yap
    feature_order = ['rom', 'true_torso_stability_left_mean', 'true_torso_stability_left_std',
                     'tempo', 'symmetry', 'true_torso_stability_right_mean',
                     'true_torso_stability_right_std', 'bilateral_true_torso_mean',
                     'bilateral_true_torso_std', 'movement_smoothness', 'peak_flexion',
                     'peak_extension', 'total_reps', 'correct_rep_ratio', 'angle_cv', 'frame_count']

    X_new = np.array([[features[k] for k in feature_order]])
    X_new_scaled = scaler.transform(X_new)

    proba = model.predict_proba(X_new_scaled)[0]
    form_score = proba[1] * 100

    # Grade
    if form_score >= 80:
        grade = "Perfect ğŸŒŸ"
    elif form_score >= 60:
        grade = "Good ğŸ‘"
    elif form_score >= 40:
        grade = "Fair âš ï¸"
    else:
        grade = "Poor âŒ"

    print(f"\n{'='*50}")
    print(f"ğŸ“Š FORM DEÄERLENDÄ°RMESÄ°")
    print(f"{'='*50}")
    print(f"  Form Skoru: {form_score:.1f}%")
    print(f"  Grade: {grade}")
    print(f"  ROM: {features['rom']:.1f}Â°")
    print(f"  Total Reps: {int(features['total_reps'])}")
    print(f"{'='*50}")

    return form_score, grade, features

# KullanÄ±m:
# predict_video('/content/drive/MyDrive/test_video.mp4')

"""---
## ğŸ“‹ Ã–zet

Bu notebook ile:
1. âœ… Videolardan MediaPipe ile aÃ§Ä±lar Ã§Ä±karÄ±ldÄ±
2. âœ… 16 biyomekanik Ã¶zellik hesaplandÄ±
3. âœ… RandomForest Classifier eÄŸitildi
4. âœ… Model deÄŸerlendirildi ve kaydedildi

### Ã‡Ä±ktÄ± DosyalarÄ±:
- `biceps_model.pkl` - EÄŸitilmiÅŸ model
- `scaler.pkl` - Feature scaler
- `feature_importance.csv` - Feature Ã¶nem sÄ±ralamasÄ±
- `feature_importance.png` - GÃ¶rselleÅŸtirme
"""