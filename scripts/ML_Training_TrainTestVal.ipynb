{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ‹ï¸ Biceps Curl Form Classifier Training\n",
        "\n",
        "Bu notebook, videolardan aÃ§Ä± Ã§Ä±kararak RandomForest Classifier modeli eÄŸitir.\n",
        "\n",
        "## Pipeline:\n",
        "1. **Video Ä°ÅŸleme**: MediaPipe ile frame-by-frame aÃ§Ä± Ã§Ä±karÄ±mÄ±\n",
        "2. **Feature Extraction**: CSV'lerden 16 biyomekanik Ã¶zellik Ã§Ä±karÄ±mÄ±\n",
        "3. **Model EÄŸitimi**: RandomForest Classifier ile sÄ±nÄ±flandÄ±rma\n",
        "4. **DeÄŸerlendirme**: Accuracy, confusion matrix, feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ 1. Paket Kurulumu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##  2. Google Drive BaÄŸlantÄ±sÄ± & Video YapÄ±sÄ±\n",
        "\n",
        "VideolarÄ±n dizin yapÄ±sÄ± ÅŸu ÅŸekilde olmalÄ±:\n",
        "`\n",
        "/content/drive/MyDrive/normal_video/\n",
        " train/\n",
        "    true/\n",
        "       true_1.mp4, true_2.mp4, ...\n",
        "    false/\n",
        "        false_1.mp4, false_2.mp4, ...\n",
        " test/\n",
        "    true/ & false/\n",
        " validation/\n",
        "     true/ & false/\n",
        "`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ 2. Google Drive BaÄŸlantÄ±sÄ± & Video YapÄ±sÄ±\n",
        "\n",
        "VideolarÄ±n dizin yapÄ±sÄ± ÅŸu ÅŸekilde olmalÄ±:\n",
        "```\n",
        "/content/drive/MyDrive/videos/\n",
        "â”œâ”€â”€ true/\n",
        "â”‚   â”œâ”€â”€ true_1.mp4\n",
        "â”‚   â”œâ”€â”€ true_2.mp4\n",
        "â”‚   â””â”€â”€ ...\n",
        "â””â”€â”€ false/\n",
        "    â”œâ”€â”€ false_1.mp4\n",
        "    â”œâ”€â”€ false_2.mp4\n",
        "    â””â”€â”€ ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Video klasÃ¶r yollarÄ±nÄ± ayarlayÄ±n\n",
        "VIDEOS_BASE_DIR = '/content/drive/MyDrive/videos'  # DeÄŸiÅŸtirin!\n",
        "TRUE_VIDEOS_DIR = f'{VIDEOS_BASE_DIR}/true'\n",
        "FALSE_VIDEOS_DIR = f'{VIDEOS_BASE_DIR}/false'\n",
        "OUTPUT_DIR = '/content/output'\n",
        "\n",
        "import os\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/csv/true', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/csv/false', exist_ok=True)\n",
        "\n",
        "print(f\"âœ“ True videos: {TRUE_VIDEOS_DIR}\")\n",
        "print(f\"âœ“ False videos: {FALSE_VIDEOS_DIR}\")\n",
        "print(f\"âœ“ Output: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ 3. Ana SÄ±nÄ±flar ve Fonksiyonlar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, Dict, List\n",
        "from collections import deque\n",
        "\n",
        "\n",
        "class BicepsCurlCounter:\n",
        "    \"\"\"Rep sayÄ±mÄ± ve form deÄŸerlendirmesi iÃ§in sÄ±nÄ±f\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.left_reps = 0\n",
        "        self.right_reps = 0\n",
        "        self.left_correct_reps = 0\n",
        "        self.right_correct_reps = 0\n",
        "        self.left_state = 'down'\n",
        "        self.right_state = 'down'\n",
        "        self.left_cycle_index = 0\n",
        "        self.right_cycle_index = 0\n",
        "        \n",
        "        # Smoothing\n",
        "        self.left_angle_history = deque(maxlen=5)\n",
        "        self.right_angle_history = deque(maxlen=5)\n",
        "        \n",
        "        # Thresholds\n",
        "        self.up_threshold = 60\n",
        "        self.down_threshold = 140\n",
        "        self.alignment_threshold = 30\n",
        "        \n",
        "    def get_smoothed_angle(self, angle, history):\n",
        "        if angle is not None:\n",
        "            history.append(angle)\n",
        "        if len(history) == 0:\n",
        "            return None\n",
        "        return sum(history) / len(history)\n",
        "    \n",
        "    def update(self, left_angle, right_angle, left_aligned, right_aligned, left_elbow_align, right_elbow_align):\n",
        "        # Smooth angles\n",
        "        left_smoothed = self.get_smoothed_angle(left_angle, self.left_angle_history)\n",
        "        right_smoothed = self.get_smoothed_angle(right_angle, self.right_angle_history)\n",
        "        \n",
        "        # Left arm rep counting\n",
        "        if left_smoothed is not None:\n",
        "            if self.left_state == 'down' and left_smoothed < self.up_threshold:\n",
        "                self.left_state = 'up'\n",
        "            elif self.left_state == 'up' and left_smoothed > self.down_threshold:\n",
        "                self.left_state = 'down'\n",
        "                self.left_reps += 1\n",
        "                self.left_cycle_index += 1\n",
        "                if left_aligned and left_elbow_align < self.alignment_threshold:\n",
        "                    self.left_correct_reps += 1\n",
        "        \n",
        "        # Right arm rep counting\n",
        "        if right_smoothed is not None:\n",
        "            if self.right_state == 'down' and right_smoothed < self.up_threshold:\n",
        "                self.right_state = 'up'\n",
        "            elif self.right_state == 'up' and right_smoothed > self.down_threshold:\n",
        "                self.right_state = 'down'\n",
        "                self.right_reps += 1\n",
        "                self.right_cycle_index += 1\n",
        "                if right_aligned and right_elbow_align < self.alignment_threshold:\n",
        "                    self.right_correct_reps += 1\n",
        "        \n",
        "        return {\n",
        "            'left_reps': self.left_reps,\n",
        "            'right_reps': self.right_reps,\n",
        "            'left_correct_reps': self.left_correct_reps,\n",
        "            'right_correct_reps': self.right_correct_reps,\n",
        "            'total_reps': self.left_reps + self.right_reps,\n",
        "            'left_state': self.left_state,\n",
        "            'right_state': self.right_state,\n",
        "            'left_cycle_index': self.left_cycle_index,\n",
        "            'right_cycle_index': self.right_cycle_index,\n",
        "            'left_smoothed_angle': left_smoothed,\n",
        "            'right_smoothed_angle': right_smoothed\n",
        "        }\n",
        "\n",
        "\n",
        "class VideoAngleExtractor:\n",
        "    \"\"\"MediaPipe kullanarak videodan aÃ§Ä± Ã§Ä±kartÄ±cÄ±\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.pose = self.mp_pose.Pose(\n",
        "            static_image_mode=False,\n",
        "            model_complexity=1,\n",
        "            smooth_landmarks=True,\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5\n",
        "        )\n",
        "        \n",
        "    def calculate_angle(self, p1, p2, p3):\n",
        "        if None in [p1, p2, p3]:\n",
        "            return None\n",
        "        v1 = np.array(p1) - np.array(p2)\n",
        "        v2 = np.array(p3) - np.array(p2)\n",
        "        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
        "        cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
        "        return np.degrees(np.arccos(cos_angle))\n",
        "    \n",
        "    def get_landmark(self, landmarks, idx, w, h):\n",
        "        if not landmarks:\n",
        "            return None\n",
        "        lm = landmarks.landmark[idx]\n",
        "        if lm.visibility < 0.5:\n",
        "            return None\n",
        "        return (lm.x * w, lm.y * h)\n",
        "    \n",
        "    def check_alignment(self, shoulder, elbow, hip, torso_height):\n",
        "        if None in [shoulder, elbow, hip]:\n",
        "            return True\n",
        "        elbow_offset = abs(elbow[0] - shoulder[0])\n",
        "        max_deviation = torso_height * 0.15\n",
        "        return elbow_offset < max_deviation\n",
        "    \n",
        "    def process_video(self, video_path: str, output_csv_path: str) -> pd.DataFrame:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Video aÃ§Ä±lamadÄ±: {video_path}\")\n",
        "        \n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        \n",
        "        counter = BicepsCurlCounter()\n",
        "        results = []\n",
        "        frame_idx = 0\n",
        "        \n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            \n",
        "            frame_idx += 1\n",
        "            h, w = frame.shape[:2]\n",
        "            \n",
        "            # MediaPipe iÅŸleme\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            pose_results = self.pose.process(frame_rgb)\n",
        "            landmarks = pose_results.pose_landmarks\n",
        "            \n",
        "            # Landmark'larÄ± al\n",
        "            left_shoulder = self.get_landmark(landmarks, 11, w, h)\n",
        "            left_elbow = self.get_landmark(landmarks, 13, w, h)\n",
        "            left_wrist = self.get_landmark(landmarks, 15, w, h)\n",
        "            left_hip = self.get_landmark(landmarks, 23, w, h)\n",
        "            \n",
        "            right_shoulder = self.get_landmark(landmarks, 12, w, h)\n",
        "            right_elbow = self.get_landmark(landmarks, 14, w, h)\n",
        "            right_wrist = self.get_landmark(landmarks, 16, w, h)\n",
        "            right_hip = self.get_landmark(landmarks, 24, w, h)\n",
        "            \n",
        "            # Kol aÃ§Ä±larÄ±nÄ± hesapla (biceps curl angle)\n",
        "            left_arm_angle = self.calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
        "            right_arm_angle = self.calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
        "            \n",
        "            # Dirsek hizalama aÃ§Ä±larÄ± (elbow-shoulder-hip)\n",
        "            left_elbow_align = self.calculate_angle(left_elbow, left_shoulder, left_hip)\n",
        "            right_elbow_align = self.calculate_angle(right_elbow, right_shoulder, right_hip)\n",
        "            \n",
        "            # True torso angles (hip-shoulder-vertical)\n",
        "            left_true_torso = None\n",
        "            right_true_torso = None\n",
        "            if left_shoulder and left_hip:\n",
        "                vertical_left = (left_shoulder[0], left_shoulder[1] - 100)\n",
        "                left_true_torso = self.calculate_angle(vertical_left, left_shoulder, left_hip)\n",
        "            if right_shoulder and right_hip:\n",
        "                vertical_right = (right_shoulder[0], right_shoulder[1] - 100)\n",
        "                right_true_torso = self.calculate_angle(vertical_right, right_shoulder, right_hip)\n",
        "            \n",
        "            # Alignment check\n",
        "            left_torso_height = abs(left_hip[1] - left_shoulder[1]) if left_hip and left_shoulder else 100\n",
        "            right_torso_height = abs(right_hip[1] - right_shoulder[1]) if right_hip and right_shoulder else 100\n",
        "            left_aligned = self.check_alignment(left_shoulder, left_elbow, left_hip, left_torso_height)\n",
        "            right_aligned = self.check_alignment(right_shoulder, right_elbow, right_hip, right_torso_height)\n",
        "            \n",
        "            # Rep counter update\n",
        "            status = counter.update(\n",
        "                left_arm_angle, right_arm_angle,\n",
        "                left_aligned, right_aligned,\n",
        "                left_elbow_align or 999, right_elbow_align or 999\n",
        "            )\n",
        "            \n",
        "            # Row oluÅŸtur\n",
        "            time_sec = frame_idx / fps if fps > 0 else 0\n",
        "            row = {\n",
        "                'frame': frame_idx,\n",
        "                'time_s': round(time_sec, 3),\n",
        "                'left_cycle_index': status['left_cycle_index'],\n",
        "                'right_cycle_index': status['right_cycle_index'],\n",
        "                'left_state': status['left_state'],\n",
        "                'right_state': status['right_state'],\n",
        "                'left_angle_raw_deg': round(left_arm_angle, 2) if left_arm_angle else '',\n",
        "                'right_angle_raw_deg': round(right_arm_angle, 2) if right_arm_angle else '',\n",
        "                'left_angle_smoothed_deg': round(status['left_smoothed_angle'], 2) if status['left_smoothed_angle'] else '',\n",
        "                'right_angle_smoothed_deg': round(status['right_smoothed_angle'], 2) if status['right_smoothed_angle'] else '',\n",
        "                'left_elbow_alignment_angle_deg': round(left_elbow_align, 2) if left_elbow_align else '',\n",
        "                'right_elbow_alignment_angle_deg': round(right_elbow_align, 2) if right_elbow_align else '',\n",
        "                'left_true_torso_angle_deg': round(left_true_torso, 2) if left_true_torso else '',\n",
        "                'right_true_torso_angle_deg': round(right_true_torso, 2) if right_true_torso else '',\n",
        "                'left_aligned': int(left_aligned),\n",
        "                'right_aligned': int(right_aligned),\n",
        "                'left_reps': status['left_reps'],\n",
        "                'right_reps': status['right_reps'],\n",
        "                'left_correct_reps': status['left_correct_reps'],\n",
        "                'right_correct_reps': status['right_correct_reps'],\n",
        "                'total_reps': status['total_reps']\n",
        "            }\n",
        "            results.append(row)\n",
        "            \n",
        "            # Progress\n",
        "            if frame_idx % 50 == 0:\n",
        "                print(f\"  {frame_idx}/{frame_count} ({100*frame_idx/frame_count:.0f}%)\", end='\\r')\n",
        "        \n",
        "        cap.release()\n",
        "        \n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(output_csv_path, index=False)\n",
        "        \n",
        "        return df\n",
        "\n",
        "\n",
        "print(\"âœ“ SÄ±nÄ±flar yÃ¼klendi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¬ 4. TÃ¼m VideolarÄ± Ä°ÅŸle ve CSV Ã‡Ä±kart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_process_videos(input_folder, output_folder, prefix, category):\n",
        "    \"\"\"Videolardan CSV Ã§Ä±kart\"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    \n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.MOV']\n",
        "    video_files = []\n",
        "    for ext in video_extensions:\n",
        "        video_files.extend(list(Path(input_folder).glob(f'{prefix}_*{ext}')))\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{category} VIDEOLARI Ä°ÅLENÄ°YOR\")\n",
        "    print(f\"Bulunan video sayÄ±sÄ±: {len(video_files)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    extractor = VideoAngleExtractor()\n",
        "    successful = 0\n",
        "    \n",
        "    for idx, video_path in enumerate(sorted(video_files), 1):\n",
        "        print(f\"\\n[{idx}/{len(video_files)}] {video_path.name}\")\n",
        "        \n",
        "        try:\n",
        "            # Video numarasÄ±nÄ± al\n",
        "            import re\n",
        "            match = re.search(r'_(\\d+)', video_path.stem)\n",
        "            video_num = match.group(1) if match else str(idx)\n",
        "            \n",
        "            output_csv = f\"{output_folder}/output_{prefix}_{video_num}.csv\"\n",
        "            df = extractor.process_video(str(video_path), output_csv)\n",
        "            print(f\"  âœ“ {len(df)} frame iÅŸlendi\")\n",
        "            successful += 1\n",
        "        except Exception as e:\n",
        "            print(f\"  âœ— Hata: {e}\")\n",
        "    \n",
        "    print(f\"\\nâœ“ {successful}/{len(video_files)} video baÅŸarÄ±yla iÅŸlendi\")\n",
        "    return successful\n",
        "\n",
        "# TRUE videolarÄ± iÅŸle\n",
        "true_count = batch_process_videos(\n",
        "    TRUE_VIDEOS_DIR, \n",
        "    f'{OUTPUT_DIR}/csv/true', \n",
        "    'true', \n",
        "    'DOÄRU FORM (true)'\n",
        ")\n",
        "\n",
        "# FALSE videolarÄ± iÅŸle\n",
        "false_count = batch_process_videos(\n",
        "    FALSE_VIDEOS_DIR, \n",
        "    f'{OUTPUT_DIR}/csv/false', \n",
        "    'false', \n",
        "    'YANLIÅ FORM (false)'\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"TOPLAM: {true_count + false_count} video iÅŸlendi\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 5. Feature Extraction (16 Ã–zellik)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(csv_path: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    CSV'den 16 biyomekanik Ã¶zellik Ã§Ä±kart:\n",
        "    - rom: Range of Motion\n",
        "    - true_torso_stability_left_mean/std: Sol gÃ¶vde stabilitesi\n",
        "    - true_torso_stability_right_mean/std: SaÄŸ gÃ¶vde stabilitesi\n",
        "    - bilateral_true_torso_mean/std: Ä°ki taraflÄ± gÃ¶vde stabilitesi\n",
        "    - tempo: Rep baÅŸÄ±na sÃ¼re\n",
        "    - symmetry: Sol-saÄŸ simetri\n",
        "    - movement_smoothness: Hareket akÄ±cÄ±lÄ±ÄŸÄ±\n",
        "    - peak_flexion/extension: Min/max aÃ§Ä±lar\n",
        "    - total_reps: Toplam rep\n",
        "    - correct_rep_ratio: DoÄŸru rep oranÄ±\n",
        "    - angle_cv: AÃ§Ä± varyasyon katsayÄ±sÄ±\n",
        "    - frame_count: Frame sayÄ±sÄ±\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        features = {}\n",
        "        \n",
        "        # 1. ROM\n",
        "        left_angles = pd.to_numeric(df['left_angle_smoothed_deg'], errors='coerce').dropna()\n",
        "        right_angles = pd.to_numeric(df['right_angle_smoothed_deg'], errors='coerce').dropna()\n",
        "        all_angles = pd.concat([left_angles, right_angles])\n",
        "        features['rom'] = float(all_angles.max() - all_angles.min()) if len(all_angles) > 0 else 0.0\n",
        "        \n",
        "        # 2-3. True Torso Stability - Left\n",
        "        left_torso = pd.to_numeric(df['left_true_torso_angle_deg'], errors='coerce').dropna()\n",
        "        features['true_torso_stability_left_mean'] = float(left_torso.mean()) if len(left_torso) > 0 else 0.0\n",
        "        features['true_torso_stability_left_std'] = float(left_torso.std()) if len(left_torso) > 0 else 0.0\n",
        "        \n",
        "        # 4. Tempo\n",
        "        total_reps = df['total_reps'].iloc[-1] if len(df) > 0 else 0\n",
        "        total_time = df['time_s'].iloc[-1] if len(df) > 0 else 0\n",
        "        features['tempo'] = float(total_time / total_reps) if total_reps > 0 else 0.0\n",
        "        \n",
        "        # 5. Symmetry\n",
        "        if len(left_angles) > 1 and len(right_angles) > 1:\n",
        "            min_len = min(len(left_angles), len(right_angles))\n",
        "            corr = np.corrcoef(left_angles.iloc[:min_len].values, right_angles.iloc[:min_len].values)[0, 1]\n",
        "            features['symmetry'] = float(corr) if not np.isnan(corr) else 0.0\n",
        "        else:\n",
        "            features['symmetry'] = 0.0\n",
        "        \n",
        "        # 6-7. True Torso Stability - Right\n",
        "        right_torso = pd.to_numeric(df['right_true_torso_angle_deg'], errors='coerce').dropna()\n",
        "        features['true_torso_stability_right_mean'] = float(right_torso.mean()) if len(right_torso) > 0 else 0.0\n",
        "        features['true_torso_stability_right_std'] = float(right_torso.std()) if len(right_torso) > 0 else 0.0\n",
        "        \n",
        "        # 8-9. Bilateral True Torso\n",
        "        all_torso = pd.concat([left_torso, right_torso])\n",
        "        features['bilateral_true_torso_mean'] = float(all_torso.mean()) if len(all_torso) > 0 else 0.0\n",
        "        features['bilateral_true_torso_std'] = float(all_torso.std()) if len(all_torso) > 0 else 0.0\n",
        "        \n",
        "        # 10. Movement Smoothness\n",
        "        all_changes = pd.concat([left_angles.diff().abs().dropna(), right_angles.diff().abs().dropna()])\n",
        "        avg_change = all_changes.mean()\n",
        "        features['movement_smoothness'] = float(1.0 / (avg_change + 1e-6)) if len(all_changes) > 0 else 0.0\n",
        "        \n",
        "        # 11-12. Peak Flexion/Extension\n",
        "        features['peak_flexion'] = float(all_angles.min()) if len(all_angles) > 0 else 0.0\n",
        "        features['peak_extension'] = float(all_angles.max()) if len(all_angles) > 0 else 0.0\n",
        "        \n",
        "        # 13. Total Reps\n",
        "        features['total_reps'] = float(total_reps)\n",
        "        \n",
        "        # 14. Correct Rep Ratio\n",
        "        left_correct = df['left_correct_reps'].iloc[-1] if len(df) > 0 else 0\n",
        "        right_correct = df['right_correct_reps'].iloc[-1] if len(df) > 0 else 0\n",
        "        total_correct = left_correct + right_correct\n",
        "        total_reps_both = total_reps * 2\n",
        "        features['correct_rep_ratio'] = float(total_correct / total_reps_both) if total_reps_both > 0 else 0.0\n",
        "        \n",
        "        # 15. Angle CV\n",
        "        angle_mean = all_angles.mean()\n",
        "        angle_std = all_angles.std()\n",
        "        features['angle_cv'] = float(angle_std / angle_mean) if angle_mean > 0 else 0.0\n",
        "        \n",
        "        # 16. Frame Count\n",
        "        features['frame_count'] = float(len(df))\n",
        "        \n",
        "        return features\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Hata: {e}\")\n",
        "        return {k: 0.0 for k in ['rom', 'true_torso_stability_left_mean', 'true_torso_stability_left_std',\n",
        "                                  'tempo', 'symmetry', 'true_torso_stability_right_mean', \n",
        "                                  'true_torso_stability_right_std', 'bilateral_true_torso_mean',\n",
        "                                  'bilateral_true_torso_std', 'movement_smoothness', 'peak_flexion',\n",
        "                                  'peak_extension', 'total_reps', 'correct_rep_ratio', 'angle_cv', 'frame_count']}\n",
        "\n",
        "print(\"âœ“ Feature extraction fonksiyonu yÃ¼klendi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ 6. Veri YÃ¼kleme ve Feature Ã‡Ä±karÄ±mÄ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(csv_base_dir):\n",
        "    \"\"\"TÃ¼m CSV'lerden feature Ã§Ä±kart ve veri seti oluÅŸtur\"\"\"\n",
        "    \n",
        "    true_csvs = sorted(glob.glob(os.path.join(csv_base_dir, 'true', 'output_true_*.csv')))\n",
        "    false_csvs = sorted(glob.glob(os.path.join(csv_base_dir, 'false', 'output_false_*.csv')))\n",
        "    \n",
        "    print(f\"Bulunan CSV'ler:\")\n",
        "    print(f\"  TRUE: {len(true_csvs)}\")\n",
        "    print(f\"  FALSE: {len(false_csvs)}\")\n",
        "    \n",
        "    features_list = []\n",
        "    labels = []\n",
        "    filenames = []\n",
        "    \n",
        "    # TRUE samples (label = 1)\n",
        "    print(\"\\nTRUE Ã¶rnekler iÅŸleniyor...\")\n",
        "    for csv_path in true_csvs:\n",
        "        features = extract_features(csv_path)\n",
        "        features_list.append(features)\n",
        "        labels.append(1)\n",
        "        filenames.append(os.path.basename(csv_path))\n",
        "    \n",
        "    # FALSE samples (label = 0)\n",
        "    print(\"FALSE Ã¶rnekler iÅŸleniyor...\")\n",
        "    for csv_path in false_csvs:\n",
        "        features = extract_features(csv_path)\n",
        "        features_list.append(features)\n",
        "        labels.append(0)\n",
        "        filenames.append(os.path.basename(csv_path))\n",
        "    \n",
        "    df_features = pd.DataFrame(features_list)\n",
        "    X = df_features.values\n",
        "    y = np.array(labels)\n",
        "    \n",
        "    print(f\"\\nVeri seti boyutu: {X.shape}\")\n",
        "    print(f\"Ã–zellikler: {list(df_features.columns)}\")\n",
        "    \n",
        "    return X, y, filenames, df_features.columns.tolist(), df_features\n",
        "\n",
        "# Veriyi yÃ¼kle\n",
        "X, y, filenames, feature_names, df_features = load_data(f'{OUTPUT_DIR}/csv')\n",
        "\n",
        "print(\"\\nâœ“ Veri yÃ¼klendi!\")\n",
        "print(f\"  Toplam Ã¶rnek: {len(y)}\")\n",
        "print(f\"  TRUE (doÄŸru form): {sum(y)}\")\n",
        "print(f\"  FALSE (yanlÄ±ÅŸ form): {len(y) - sum(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature istatistikleri\n",
        "print(\"\\nğŸ“Š FEATURE Ä°STATÄ°STÄ°KLERÄ°:\")\n",
        "print(\"=\"*60)\n",
        "df_features.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– 7. RandomForest Model EÄŸitimi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"EÄŸitim seti: {len(X_train)} Ã¶rnek\")\n",
        "print(f\"Test seti: {len(X_test)} Ã¶rnek\")\n",
        "print(f\"EÄŸitim daÄŸÄ±lÄ±mÄ±: TRUE={sum(y_train)}, FALSE={len(y_train)-sum(y_train)}\")\n",
        "print(f\"Test daÄŸÄ±lÄ±mÄ±: TRUE={sum(y_test)}, FALSE={len(y_test)-sum(y_test)}\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# RandomForest eÄŸitimi\n",
        "print(\"\\nğŸ¤– RandomForest eÄŸitiliyor...\")\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print(\"âœ“ Model eÄŸitildi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 8. Model DeÄŸerlendirmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tahminler\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"MODEL DEÄERLENDÄ°RMESÄ°\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nğŸ¯ Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nğŸ“Š Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['YanlÄ±ÅŸ Form (0)', 'DoÄŸru Form (1)']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\nğŸ“Š Confusion Matrix:\")\n",
        "print(f\"                  Tahmin\")\n",
        "print(f\"                  0        1\")\n",
        "print(f\"GerÃ§ek  0        {cm[0,0]:3d}      {cm[0,1]:3d}\")\n",
        "print(f\"        1        {cm[1,0]:3d}      {cm[1,1]:3d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nğŸ“ˆ FEATURE IMPORTANCE (Ã–nem SÄ±rasÄ±na GÃ¶re):\")\n",
        "print(\"=\"*60)\n",
        "print(feature_importance.to_string(index=False))\n",
        "\n",
        "# GÃ¶rselleÅŸtirme\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(range(len(feature_importance)), feature_importance['importance'].values, color='steelblue')\n",
        "plt.yticks(range(len(feature_importance)), feature_importance['feature'].values)\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Feature Importance - Biceps Curl Form Classification', fontsize=14, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nâœ“ Grafik kaydedildi: {OUTPUT_DIR}/feature_importance.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¾ 9. Modeli Kaydet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model ve scaler'Ä± kaydet\n",
        "model_path = f'{OUTPUT_DIR}/biceps_model.pkl'\n",
        "scaler_path = f'{OUTPUT_DIR}/scaler.pkl'\n",
        "\n",
        "joblib.dump(model, model_path)\n",
        "joblib.dump(scaler, scaler_path)\n",
        "\n",
        "# Feature importance CSV\n",
        "feature_importance.to_csv(f'{OUTPUT_DIR}/feature_importance.csv', index=False)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"âœ“ MODEL KAYDEDÄ°LDÄ°\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"  Model: {model_path}\")\n",
        "print(f\"  Scaler: {scaler_path}\")\n",
        "print(f\"  Feature Importance: {OUTPUT_DIR}/feature_importance.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¥ 10. DosyalarÄ± Ä°ndir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Model dosyalarÄ±nÄ± indir\n",
        "print(\"Model dosyalarÄ± indiriliyor...\")\n",
        "files.download(model_path)\n",
        "files.download(scaler_path)\n",
        "files.download(f'{OUTPUT_DIR}/feature_importance.csv')\n",
        "files.download(f'{OUTPUT_DIR}/feature_importance.png')\n",
        "\n",
        "print(\"\\nâœ“ TÃ¼m dosyalar indirildi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® 11. Yeni Video Test Etme (Opsiyonel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_video(video_path):\n",
        "    \"\"\"Yeni bir video iÃ§in form skoru hesapla\"\"\"\n",
        "    \n",
        "    print(f\"Video iÅŸleniyor: {video_path}\")\n",
        "    \n",
        "    # GeÃ§ici CSV oluÅŸtur\n",
        "    temp_csv = '/content/temp_video.csv'\n",
        "    extractor = VideoAngleExtractor()\n",
        "    df = extractor.process_video(video_path, temp_csv)\n",
        "    \n",
        "    # Feature Ã§Ä±kart\n",
        "    features = extract_features(temp_csv)\n",
        "    \n",
        "    # Tahmin yap\n",
        "    feature_order = ['rom', 'true_torso_stability_left_mean', 'true_torso_stability_left_std',\n",
        "                     'tempo', 'symmetry', 'true_torso_stability_right_mean', \n",
        "                     'true_torso_stability_right_std', 'bilateral_true_torso_mean',\n",
        "                     'bilateral_true_torso_std', 'movement_smoothness', 'peak_flexion',\n",
        "                     'peak_extension', 'total_reps', 'correct_rep_ratio', 'angle_cv', 'frame_count']\n",
        "    \n",
        "    X_new = np.array([[features[k] for k in feature_order]])\n",
        "    X_new_scaled = scaler.transform(X_new)\n",
        "    \n",
        "    proba = model.predict_proba(X_new_scaled)[0]\n",
        "    form_score = proba[1] * 100\n",
        "    \n",
        "    # Grade\n",
        "    if form_score >= 80:\n",
        "        grade = \"Perfect ğŸŒŸ\"\n",
        "    elif form_score >= 60:\n",
        "        grade = \"Good ğŸ‘\"\n",
        "    elif form_score >= 40:\n",
        "        grade = \"Fair âš ï¸\"\n",
        "    else:\n",
        "        grade = \"Poor âŒ\"\n",
        "    \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"ğŸ“Š FORM DEÄERLENDÄ°RMESÄ°\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"  Form Skoru: {form_score:.1f}%\")\n",
        "    print(f\"  Grade: {grade}\")\n",
        "    print(f\"  ROM: {features['rom']:.1f}Â°\")\n",
        "    print(f\"  Total Reps: {int(features['total_reps'])}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    return form_score, grade, features\n",
        "\n",
        "# KullanÄ±m:\n",
        "# predict_video('/content/drive/MyDrive/test_video.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“‹ Ã–zet\n",
        "\n",
        "Bu notebook ile:\n",
        "1. âœ… Videolardan MediaPipe ile aÃ§Ä±lar Ã§Ä±karÄ±ldÄ±\n",
        "2. âœ… 16 biyomekanik Ã¶zellik hesaplandÄ±\n",
        "3. âœ… RandomForest Classifier eÄŸitildi\n",
        "4. âœ… Model deÄŸerlendirildi ve kaydedildi\n",
        "\n",
        "### Ã‡Ä±ktÄ± DosyalarÄ±:\n",
        "- `biceps_model.pkl` - EÄŸitilmiÅŸ model\n",
        "- `scaler.pkl` - Feature scaler\n",
        "- `feature_importance.csv` - Feature Ã¶nem sÄ±ralamasÄ±\n",
        "- `feature_importance.png` - GÃ¶rselleÅŸtirme"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}